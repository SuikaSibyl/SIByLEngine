#version 460
#extension GL_GOOGLE_include_directive : enable

struct PushConstants { 
    uvec2 resolution;
    uint sample_batch; 
};
layout(push_constant) uniform PushConsts { PushConstants pushConstants; };

#include "../include/common_trace.h"
#include "../include/common_sample_shape.h"
#include "../../../Utility/random.h"
#include "../../../Utility/sampling.h"

layout(location = 0) rayPayloadEXT PrimaryPayload   rPrimaryPld;
layout(location = 1) rayPayloadEXT ShadowPayload    rShadowPld;

layout(location = 0) callableDataEXT SampleQuery cSampleQuery;

struct PathVertex {
    vec3 position;
    bool intersected;
};

struct Ray {
    vec3    origin;
    float   tnear;
    vec3    direction;
    float   tfar;
};

vec3 skyColor(in vec3 rayDir) {
    const float t = 0.5 * (rayDir.y + 1.0);
    return (1.0-t)*vec3(1.0) + t*vec3(0.5, 0.7, 1.0);
}

float pdf_sample_bsdf_lambertian(
    in mat3 TBN,
    in vec3 dir_in,
    in vec3 dir_out) 
{
    vec3 normal = TBN[2];
    if (dot(normal, dir_in) < 0 ||
            dot(normal, dir_out) < 0) {
        // No light below the surface
        return 0.f;
    }
    // Flip the shading frame if it is inconsistent with the geometry normal
    // For Lambertian, we importance sample the cosine hemisphere domain.
    return max(dot(normal, dir_out), 0.f) / k_pi;
}

PathVertex tracePrimaryRay(in Ray ray) {
    traceRayEXT(tlas,              // Top-level acceleration structure
            gl_RayFlagsOpaqueEXT,  // Ray flags, here saying "treat all geometry as opaque"
            0xFF,                  // 8-bit instance mask, here saying "trace against all instances"
            0,                     // SBT record offset
            0,                     // SBT record stride for offset
            0,                     // Miss index
            ray.origin,            // Ray origin
            ray.tnear,             // Minimum t-value
            ray.direction,         // Ray direction
            ray.tfar,              // Maximum t-value
            0);                    // Location of payload
    PathVertex vertex;
    vertex.position = rPrimaryPld.position;
    vertex.intersected = getIntersected(rPrimaryPld.flags);
    return vertex;
}

vec3 unidirectional_path_tracing(in Ray ray, in uint RNG) {
    // 
    vec3 radiance = vec3(0);
    vec3 path_throughput = vec3(1);

    // primary intersection
    PathVertex vertex = tracePrimaryRay(ray);
    if(!vertex.intersected) {
        // TODO:: add background / env map
        // return skyColor(ray.direction);
        return vec3(0,0,0);
    }
    // eta_scale stores the scale introduced by Snell-Descartes law to the BSDF (eta^2).
    // We use the same Russian roulette strategy as Mitsuba/pbrt-v3
    // and tracking eta_scale and removing it from the
    // path contribution is crucial for many bounces of refraction.
    float eta_scale = 1.f;
    // TODO :: check whether hit a light source
    // We hit a light immediately. 
    // This path has only two vertices and has contribution
    // C = W(v0, v1) * G(v0, v1) * L(v0, v1)
    // if (is_light(scene.shapes[vertex.shape_id])) {
    //     radiance += path_throughput *
    //         emission(vertex, -ray.dir, scene);
    // }

    
    // We iteratively sum up path contributions from paths with different number of vertices
    // If max_depth == -1, we rely on Russian roulette for path termination.
    for (int num_vertices = 3; MAX_DEPTH == -1 || num_vertices <= 4; ++num_vertices) {
        MaterialData material = materials[rPrimaryPld.matID];
        vec3 baseColor = texture(textures[material.basecolor_opacity_tex], rPrimaryPld.uv).rgb;
        cSampleQuery.ref_point = rPrimaryPld.position;
        cSampleQuery.geometry_id = 2; // TODO :: flexible ID
        cSampleQuery.uv = vec2(stepAndOutputRNGFloat(RNG), stepAndOutputRNGFloat(RNG));
        executeCallableEXT(0, 0);
        const vec3 lightPos = cSampleQuery.position;
        const vec3 lightNormal = cSampleQuery.normal;
        const vec3 shadowRayOrigin = offsetPositionAlongNormal(rPrimaryPld.position, rPrimaryPld.TBN[2]);
        const vec3 lightSample = lightPos;
        const vec3 lightDir = normalize(lightSample - shadowRayOrigin);
        // If the point on light is occluded, G is 0. So we need to test for occlusion.
        // To avoid self intersection, we need to set the tnear of the ray
        // to a small "epsilon". We set the epsilon to be a small constant times the
        // scale of the scene, which we can obtain through the get_shadow_epsilon() function.
        // TODO:: Fix this
        const float lightDist = length(lightSample - shadowRayOrigin) - 0.001;
        rShadowPld.occluded = false;            
        traceRayEXT(tlas,           // Top-level acceleration structure
            gl_RayFlagsOpaqueEXT,   // Ray flags, here saying "treat all geometry as opaque"
            0xFF,                   // 8-bit instance mask, here saying "trace against all instances"
            PRIMITIVE_TYPE_COUNT,   // SBT record offset
            0,                      // SBT record stride for offset
            1,                      // Miss index
            shadowRayOrigin,        // Ray origin
            0.0,                    // Minimum t-value
            lightDir,               // Ray direction
            lightDist,              // Maximum t-value
            1);                     // Location of payload
        if(!rShadowPld.occluded && num_vertices!=3)
            radiance += path_throughput * baseColor;

        vec2 bsdf_uv = vec2(stepAndOutputRNGFloat(RNG), stepAndOutputRNGFloat(RNG));
        vec3 dir_bsdf = rPrimaryPld.TBN * cosineSampleHemisphere(bsdf_uv);

        // Trace a ray towards bsdf_dir. Note that again we have
        // to have an "epsilon" tnear to prevent self intersection.
        const vec3 recursiveRayOrigin = offsetPositionAlongNormal(rPrimaryPld.position, rPrimaryPld.TBN[2]);
        Ray bsdf_ray;
        bsdf_ray.origin     = recursiveRayOrigin;
        bsdf_ray.tnear      = 0; // get_intersection_epsilon(scene);
        bsdf_ray.direction  = dir_bsdf;
        bsdf_ray.tfar       = T_MAX;
        PathVertex vertex = tracePrimaryRay(bsdf_ray);
        if(!vertex.intersected) {
            // TODO:: add background / env map
            // return skyColor(ray.direction);
            break;
        }
        ray = bsdf_ray;
        
        // // Remember "path_throughput" already stores all the path contribution on and before v_i.
        // // So we only need to compute G(v_{i}, v_{i+1}) * f(v_{i-1}, v_{i}, v_{i+1}) * L(v_{i}, v_{i+1})

        // MaterialData material = materials[rPrimaryPld.matID];
        
        // // First, we sample a point on the light source.
        // // We do this by first picking a light source, then pick a point on it.
        // // TODO: sample light sources
        // cSampleQuery.ref_point = rPrimaryPld.position;
        // cSampleQuery.geometry_id = 2; // TODO :: flexible ID
        // cSampleQuery.uv = vec2(stepAndOutputRNGFloat(RNG), stepAndOutputRNGFloat(RNG));
        // executeCallableEXT(0, 0);
        // const vec3 lightPos = cSampleQuery.position;
        // const vec3 lightNormal = cSampleQuery.normal;

        // // Next, we compute w1*C1/p1. We store C1/p1 in C1.
        // vec3 C1 = vec3(0.f);
        // float w1 = 0;
        // // Remember "path_throughput" already stores all the path contribution on and before v_i.
        // // So we only need to compute G(v_{i}, v_{i+1}) * f(v_{i-1}, v_{i}, v_{i+1}) * L(v_{i}, v_{i+1})
        // {
        //     // Let's first deal with C1 = G * f * L.
        //     // Let's first compute G.
        //     float G = 0;
        //     vec3 dir_light;
        //     // The geometry term is different between directional light sources and
        //     // others. Currently we only have environment maps as directional light sources.
        //     if(true){
        //         const vec3 shadowRayOrigin = offsetPositionAlongNormal(rPrimaryPld.position, rPrimaryPld.TBN[2]);
        //         const vec3 lightSample = lightPos;
        //         const vec3 lightDir = normalize(lightSample - shadowRayOrigin);
        //         // If the point on light is occluded, G is 0. So we need to test for occlusion.
        //         // To avoid self intersection, we need to set the tnear of the ray
        //         // to a small "epsilon". We set the epsilon to be a small constant times the
        //         // scale of the scene, which we can obtain through the get_shadow_epsilon() function.
        //         // TODO:: Fix this
        //         const float lightDist = length(lightSample - shadowRayOrigin) - 0.001;
        //         rShadowPld.occluded = false;            
        //         traceRayEXT(tlas,           // Top-level acceleration structure
        //             gl_RayFlagsOpaqueEXT,   // Ray flags, here saying "treat all geometry as opaque"
        //             0xFF,                   // 8-bit instance mask, here saying "trace against all instances"
        //             PRIMITIVE_TYPE_COUNT,   // SBT record offset
        //             0,                      // SBT record stride for offset
        //             1,                      // Miss index
        //             shadowRayOrigin,        // Ray origin
        //             0.0,                    // Minimum t-value
        //             lightDir,               // Ray direction
        //             lightDist,              // Maximum t-value
        //             1);                     // Location of payload
        //         if(!rShadowPld.occluded) {
        //             G = 1;
        //         }
        //     }
        //     else {
        //     // if is_envmap
        //     // TODO :: add envmap
        //     }

        //     // Before we proceed, we first compute the probability density p1(v1)
        //     // The probability density for light sampling to sample our point is
        //     // just the probability of sampling a light times the probability of sampling a point
        //     float p1 = 1;
        //     // TODO :: Fix light_pmf(scene, light_id) *
        //     //             pdf_point_on_light(light, point_on_light, vertex.position, scene);

        //     // We don't need to continue the computation if G is 0.
        //     // Also sometimes there can be some numerical issue such that we generate
        //     // a light path with probability zero
        //     if (G > 0 && p1 > 0) {
        //         // Let's compute f (BSDF) next.
        //         vec3 dir_view = -ray.direction;
        //         // TODO :: fix f computation
        //         // vec3 f = eval(mat, dir_view, dir_light, vertex);
        //         vec3 f = texture(textures[material.basecolor_opacity_tex], rPrimaryPld.uv).rgb;
        //         // Evaluate the emission
        //         // We set the footprint to zero since it is not fully clear how
        //         // to set it in this case.
        //         // One way is to use a roughness based heuristics, but we have multi-layered BRDFs.
        //         // See "Real-time Shading with Filtered Importance Sampling" from Colbert et al.
        //         // for the roughness based heuristics.
        //         // TODO :: fix L computation
        //         // vec3 L = emission(light, -dir_light, 0.f, point_on_light, scene);
        //         vec3 L = vec3(1.f);
        //         // C1 is just a product of all of them!
        //         C1 = G * f * L;
                
        //         // Next let's compute w1

        //         // Remember that we want to set
        //         // w1 = p_1(v^1)^2 / (p_1(v^1)^2 + p_2(v^1)^2)
        //         // Notice that all of the probability density share the same path prefix and those cancel out.
        //         // Therefore we only need to account for the generation of the vertex v_{i+1}.

        //         // The probability density for our hemispherical sampling to sample
        //         // TODO :: fix p2 computation
        //         // float p2 = pdf_sample_bsdf(mat, dir_view, dir_light, vertex, scene.texture_pool);
        //         float p2 = pdf_sample_bsdf_lambertian(rPrimaryPld.TBN, dir_view, dir_light);
        //         // !!!! IMPORTANT !!!!
        //         // In general, p1 and p2 now live in different spaces!!
        //         // our BSDF API outputs a probability density in the solid angle measure
        //         // while our light probability density is in the area measure.
        //         // We need to make sure that they are in the same space.
        //         // This can be done by accounting for the Jacobian of the transformation
        //         // between the two measures.
        //         // In general, I recommend to transform everything to area measure 
        //         // (except for directional lights) since it fits to the path-space math better.
        //         // Converting a solid angle measure to an area measure is just a
        //         // multiplication of the geometry term G (let solid angle be dS, area be dA,
        //         // we have dA/dS = G).
        //         p2 *= G;

        //         w1 = (p1*p1) / (p1*p1 + p2*p2);
        //         C1 /= p1;
        //     }
        // }
        // radiance += path_throughput * C1 * w1;

        // // Let's do the hemispherical sampling next.
        // vec3 dir_view = -ray.direction;
        // vec2 bsdf_rnd_param_uv = vec2(stepAndOutputRNGFloat(RNG), stepAndOutputRNGFloat(RNG));
        // // float bsdf_rnd_param_w = stepAndOutputRNGFloat(RNG);

        // // // std::optional<BSDFSampleRecord> bsdf_sample_ =
        // // //     sample_bsdf(mat,
        // // //                 dir_view,
        // // //                 vertex,
        // // //                 scene.texture_pool,
        // // //                 bsdf_rnd_param_uv,
        // // //                 bsdf_rnd_param_w);
        // // if (!bsdf_sample_) {
        // //     // BSDF sampling failed. Abort the loop.
        // //     break;
        // // }
        // // const BSDFSampleRecord &bsdf_sample = *bsdf_sample_;
        // // Vector3 dir_bsdf = bsdf_sample.dir_out;
        // vec3 dir_bsdf = rPrimaryPld.TBN * cosineSampleHemisphere(bsdf_rnd_param_uv);

        // // Trace a ray towards bsdf_dir. Note that again we have
        // // to have an "epsilon" tnear to prevent self intersection.
        // const vec3 recursiveRayOrigin = offsetPositionAlongNormal(rPrimaryPld.position, rPrimaryPld.TBN[2]);
        // Ray bsdf_ray;
        // bsdf_ray.origin     = recursiveRayOrigin;
        // bsdf_ray.tnear      = 0; // get_intersection_epsilon(scene);
        // bsdf_ray.direction  = dir_bsdf;
        // bsdf_ray.tfar       = T_MAX;
        // // trace recursive primary ray
        // PathVertex bsdf_vertex = tracePrimaryRay(bsdf_ray);
        // // To update path_throughput
        // // we need to multiply G(v_{i}, v_{i+1}) * f(v_{i-1}, v_{i}, v_{i+1}) to it
        // // and divide it with the pdf for getting v_{i+1} using hemisphere sampling.
        // float G;        
        // if(bsdf_vertex.intersected) {
        //     G = abs(dot(dir_bsdf, rPrimaryPld.TBN[2])) /
        //         distance_squared(bsdf_vertex.position, vertex.position); // cos/d2
        // } else {
        //     // We hit nothing, set G to 1 to account for the environment map contribution.
        //     G = 1;
        // }
        // vec3 f = texture(textures[material.basecolor_opacity_tex], rPrimaryPld.uv).rgb;
        // float p2 = pdf_sample_bsdf_lambertian(rPrimaryPld.TBN, dir_view, dir_bsdf);
        // if (p2 <= 0) {
        //     // Numerical issue -- we generated some invalid rays.
        //     break;
        // }

        // // Remember to convert p2 to area measure!
        // p2 *= G;
        // // note that G cancels out in the division f/p, but we still need
        // // G later for the calculation of w2.

        // // Now we want to check whether dir_bsdf hit a light source, and
        // // account for the light contribution (C2 & w2 & p2).
        // // There are two possibilities: either we hit an emissive surface,
        // // or we hit an environment map.
        // // We will handle them separately.
        // // if (bsdf_vertex && is_light(scene.shapes[bsdf_vertex->shape_id])) {
            
        // // }
        // // else if (!bsdf_vertex && has_envmap(scene)) {
        // // }

        // if (!bsdf_vertex.intersected) {
        //     // Hit nothing -- can't continue tracing.
        //     break;
        // }

        // // TODO :: Russian roulette
        // // // Update rays/intersection/path_throughput/current_pdf
        // // // Russian roulette heuristics
        // float rr_prob = 1;
        // // if (num_vertices - 1 >= scene.options.rr_depth) {
        // //     rr_prob = min(max((1 / eta_scale) * path_throughput), Real(0.95));
        // //     if (next_pcg32_real<Real>(rng) > rr_prob) {
        // //         // Terminate the path
        // //         break;
        // //     }
        // // }

        // ray = bsdf_ray;
        // vertex = bsdf_vertex;
        // path_throughput *= (G * f) / (p2 * rr_prob);
    }

    return radiance;
}

void main() {
    // The resolution of the image, which is the same as the launch size:
    const ivec2 resolution = ivec2(pushConstants.resolution);
    const ivec2 pixel = ivec2(gl_LaunchIDEXT.xy);
    // If the pixel is outside of the image, don't do anything:
    if((pixel.x >= resolution.x) || (pixel.y >= resolution.y)) {
        return;
    }
    
    // As we only use 1spp, no random offset.
    const vec2 pixelCenter  = vec2(pixel.xy) + vec2(0.5);
    const vec2 inUV         = pixelCenter/vec2(resolution.xy);
    const vec2 d            = inUV * 2.0 - 1.0;

    const float focus_dist = 0.0f;
    const float length_radius = 0.;
    const vec3 targetOnFocusPlane = (globalUniform.projInverse * vec4(d.x, d.y, 1, 1)).xyz;
    const vec2 diskSample = vec2(0);
    // const vec2 diskSample = uniformSampleDisk(vec2(stepAndOutputRNGFloat(pld.rngState), stepAndOutputRNGFloat(pld.rngState)));
    const vec3 sampleOnApeture = vec3(length_radius * diskSample, 0);
    const vec4 origin       = globalUniform.viewInverse * vec4(vec3(0), 1);
    const vec4 direction    = globalUniform.viewInverse * vec4(normalize(targetOnFocusPlane - sampleOnApeture), 0);
 
    uint RNG = uint((pushConstants.sample_batch * resolution.y + pixel.y) * resolution.x + pixel.x);

    Ray primaryRay;
    primaryRay.origin       = origin.xyz;
    primaryRay.direction    = normalize(direction.xyz);
    primaryRay.tnear        = 0.0;
    primaryRay.tfar         = 10000.0;
    vec3 pixelColor = unidirectional_path_tracing(primaryRay, RNG);

    if(pushConstants.sample_batch != 0) {
        vec3 color = imageLoad(storageImage, ivec2(pixel)).rgb;
        pixelColor = (pushConstants.sample_batch * color + pixelColor) / (pushConstants.sample_batch + 1);
    }
    imageStore(storageImage, pixel, vec4(pixelColor, 1.0));
}